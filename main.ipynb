{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679d5f32",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aebffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "data_path = \"./Data\"\n",
    "file_name = os.listdir(data_path)\n",
    "file_path = [os.path.join(data_path, name) for name in file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509e7489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Data\\\\easy_sentence.txt', './Data\\\\gold.txt', './Data\\\\gold_sentence.txt', './Data\\\\hard_sentence.txt']\n"
     ]
    }
   ],
   "source": [
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a1b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_sentence = io.open(\"./Data/easy_sentence.txt\", encoding=\"utf-8\").readlines()\n",
    "hard_sentence = io.open(\"./Data/hard_sentence.txt\", encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f69435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentence = easy_sentence\n",
    "data_sentence.extend(hard_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf98592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành phố washington có một kiến trúc rất đa dạng\\n',\n",
       " 'tuy nhiên vì gặp nhiều khó khăn trong cuộc sống ông dần trở nên khó tính\\n',\n",
       " 'khí hậu hồng kông thuộc kiểu cận nhiệt đới và chịu ảnh hưởng của gió mùa\\n',\n",
       " 'khoảng hơn 70 bề mặt trái đất được bao phủ bởi các đại dương nước mặn phần còn lại là các lục địa và các đảo\\n',\n",
       " 'đà lạt là thành phố trực thuộc tỉnh lâm đồng nằm trên cao nguyên lâm viên thuộc vùng tây nguyên việt nam\\n',\n",
       " 'đổi đất đai lấy hạ tầng là một trong những việc phải làm trong bối cảnh hiện nay\\n',\n",
       " 'cuối tuần trước tôi về quê vì gia đình có đám\\n',\n",
       " 'những cơn gió căng tràng vi vu khắp núi rừng đà lạt khiến những quả hồng uống no nê những giọt sương mờ\\n',\n",
       " 'nhưng đó là chuyện đã qua\\n',\n",
       " 'biến đổi khí hậu đe doạ đến con người khi nó gây bất an lương thực khan hiếm nước lũ lụt nắng nóng cực đoan thiệt hại kinh tế và di cư\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00963a2",
   "metadata": {},
   "source": [
    "# Tách từ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82f1b2",
   "metadata": {},
   "source": [
    "## Longest Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e640188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata as ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0963637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllablize(sentence):\n",
    "    word = '\\w+'\n",
    "    non_word = '[^\\w\\s]'\n",
    "    digits = '\\d+([\\.,_]\\d+)+'\n",
    "    \n",
    "    patterns = []\n",
    "    patterns.extend([word, non_word, digits])\n",
    "    patterns = f\"({'|'.join(patterns)})\"\n",
    "    \n",
    "    sentence = ud.normalize('NFC', sentence)\n",
    "    tokens = re.findall(patterns, sentence, re.UNICODE)\n",
    "    return [token[0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8327241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_grams(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        words = f.read().splitlines() \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458a0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_matching(sentence, bi_grams, tri_grams):\n",
    "    syllables = syllablize(sentence)\n",
    "    syl_len = len(syllables)\n",
    "    \n",
    "    curr_id = 0\n",
    "    word_list = []\n",
    "    done = False\n",
    "    \n",
    "    while (curr_id < syl_len) and (not done):\n",
    "        curr_word = syllables[curr_id]\n",
    "        if curr_id >= syl_len - 1:\n",
    "            word_list.append(curr_word)\n",
    "            done = True\n",
    "        else:\n",
    "            next_word = syllables[curr_id + 1]\n",
    "            pair_word = ' '.join([curr_word.lower(), next_word.lower()])\n",
    "            if curr_id >= (syl_len - 2):\n",
    "                if pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "            else:\n",
    "                next_next_word = syllables[curr_id + 2]\n",
    "                triple_word = ' '.join([pair_word, next_next_word.lower()])\n",
    "                if triple_word in tri_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word, next_next_word]))\n",
    "                    curr_id += 3\n",
    "                elif pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6439ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = load_n_grams('./Vocab/vocab_bi_gram.txt')\n",
    "tri_grams = load_n_grams('./Vocab/vocab_tri_gram.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e883a998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận nhiệt_đới và chịu ảnh_hưởng của gió mùa']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Token/longest_matching_tokens.txt', 'w', encoding='utf-8') as f:\n",
    "    longest_matching_sentences = []\n",
    "    for sentence in data_sentence:\n",
    "        word_list = longest_matching(sentence, bi_grams, tri_grams)\n",
    "        longest_matching_sentences.append(' '.join(word_list))\n",
    "        f.write(' '.join(word_list) + '\\n')\n",
    "longest_matching_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b540c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching: 224\n"
     ]
    }
   ],
   "source": [
    "count_longest_matching_compounds = 0\n",
    "for sentence in longest_matching_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_longest_matching_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching:', count_longest_matching_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f0b36",
   "metadata": {},
   "source": [
    "## VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5029bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_vncorenlp\n",
    "model = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\", \"pos\"], save_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d9b1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận_nhiệt_đới và chịu ảnh_hưởng của gió_mùa']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Token/vncore_tokens.txt', 'w', encoding='utf-8') as f:\n",
    "    vncore_sentences = []\n",
    "    for sentence in data_sentence:\n",
    "        words = model.word_segment(sentence)[0]\n",
    "        vncore_sentences.append(words)\n",
    "        f.write(words + '\\n')\n",
    "vncore_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4065fd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ bằng thư viện VnCoreNLP: 231\n"
     ]
    }
   ],
   "source": [
    "count_vncore_compounds = 0\n",
    "for sentence in vncore_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_vncore_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ bằng thư viện VnCoreNLP:', count_vncore_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5be61b",
   "metadata": {},
   "source": [
    "## Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69e407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_sentence = io.open(\"./Data/gold_sentence.txt\", encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8455dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận_nhiệt_đới và chịu ảnh_hưởng của gió_mùa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_tokenize_sentences = []\n",
    "for sentence in gold_sentence:\n",
    "    if sentence != '\\n': \n",
    "        manual_tokenize_sentences.append(sentence.strip())\n",
    "manual_tokenize_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e83360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ thủ công: 256\n"
     ]
    }
   ],
   "source": [
    "count_manual_tokenize_compounds = 0\n",
    "for sentence in manual_tokenize_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_manual_tokenize_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ thủ công:', count_manual_tokenize_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e8113",
   "metadata": {},
   "source": [
    "## Đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecc06e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b4143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct_words(pred, source, n_grams=3):\n",
    "    pred_words = pred.split()\n",
    "    source_words = source.split()\n",
    "    \n",
    "    total_true, tp = 0, 0\n",
    "    total_errors, fp = 0, 0\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < len(pred_words):\n",
    "        if pred_words[idx] not in source_words[idx:(idx + n_grams)]: \n",
    "            if '_' in pred_words[idx]: fp += 1\n",
    "            del pred_words[idx]\n",
    "            total_errors += 1\n",
    "        else: idx += 1\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < len(source_words):\n",
    "        if source_words[idx] not in pred_words[idx:(idx + n_grams)]: \n",
    "            del source_words[idx]\n",
    "        else: idx += 1\n",
    "    \n",
    "    if len(pred_words) < len(source_words): words = pred_words\n",
    "    else: words = source_words\n",
    "    \n",
    "    for idx in range (len(words)):\n",
    "        if pred_words[idx] == source_words[idx]:\n",
    "            if '_' in pred_words[idx]: tp += 1 \n",
    "            total_true += 1\n",
    "                    \n",
    "    return total_true, total_errors, tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81f2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_evaluation(pred, source, n_grams=3):\n",
    "    total_true = 0\n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    pred_tp = 0\n",
    "    pred_fp = 0\n",
    "    \n",
    "    for pred_sentence, source_sentence in zip(pred, source):\n",
    "        total_words += len(source_sentence.split())\n",
    "        if pred_sentence != source_sentence:\n",
    "            true, error, tp, fp = count_correct_words(pred_sentence, source_sentence, n_grams)\n",
    "            total_true += true \n",
    "            total_errors += error\n",
    "            pred_tp += tp\n",
    "            pred_fp += fp\n",
    "        else:\n",
    "            for word in source_sentence.split():\n",
    "                if '_' in word:\n",
    "                    pred_tp += 1\n",
    "                total_true += 1\n",
    "                    \n",
    "    accuracy = total_true / total_words\n",
    "    precision = pred_tp / (pred_tp + pred_fp)\n",
    "    recall = pred_tp / count_manual_tokenize_compounds\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return {\n",
    "        'Accuracy': accuracy, \n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'True Positive': pred_tp, \n",
    "        'False Positive': pred_fp,\n",
    "        'Total True': total_true, \n",
    "        'Total Errors': total_errors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2206c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longest Matching</th>\n",
       "      <th>VnCoreNLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.943723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.895277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>213</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total True</th>\n",
       "      <td>665</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Errors</th>\n",
       "      <td>99</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Longest Matching VnCoreNLP\n",
       "Accuracy               0.904762  0.914286\n",
       "Precision              0.950893  0.943723\n",
       "Recall                 0.832031  0.851562\n",
       "F1                       0.8875  0.895277\n",
       "True Positive               213       218\n",
       "False Positive               11        13\n",
       "Total True                  665       672\n",
       "Total Errors                 99        81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_matching_evaluation = tokenize_evaluation(longest_matching_sentences, manual_tokenize_sentences)\n",
    "vncore_evaluation = tokenize_evaluation(vncore_sentences, manual_tokenize_sentences)\n",
    "pd.DataFrame(\n",
    "    [longest_matching_evaluation, vncore_evaluation], \n",
    "    index = ['Longest Matching', 'VnCoreNLP']\n",
    ").astype(object).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69df03",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e541d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d36ddbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố/N washington/N có/V 1/M kiến_trúc/N rất/R đa_dạng/A\\n',\n",
       " 'tuy_nhiên/C vì/C gặp/V nhiều/A khó_khăn/N trong/E cuộc_sống/N ông/N dần/R trở_nên/V khó_tính/A\\n',\n",
       " 'khí_hậu/N hồng_kông/N thuộc/V kiểu/N cận_nhiệt_đới/N và/C chịu/V ảnh_hưởng/V của/E gió_mùa/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " 'đà_lạt/N là/V thành_phố/N trực_thuộc/V tỉnh/N lâm_đồng/N nằm/V trên/E cao_nguyên/N lâm_viên/N thuộc/V vùng/N tây_nguyên/N việt_nam/N\\n',\n",
       " 'đổi/V đất_đai/N lấy/V hạ_tầng/N là/V 1/M trong/E những/D việc/N phải/V làm/V trong/E bối_cảnh/N hiện_nay/N\\n',\n",
       " 'cuối/N tuần/N trước/N tôi/P về/V quê/N vì/E gia_đình/N có/V đám/N\\n',\n",
       " 'những/D cơn_gió/N căng_tràng/A vi_vu/V khắp/A núi_rừng/N đà_lạt/N khiến/V những/D quả/N hồng/N uống/V no_nê/A những/D giọt_sương/N mờ/A\\n',\n",
       " 'nhưng/C đó/P là/V chuyện/N đã/R qua/V\\n',\n",
       " 'biến_đổi/N khí_hậu/N đe_doạ/V đến/E con_người/N khi/C nó/P gây/V bất_an/A lương_thực/N khan_hiếm/A nước/N lũ_lụt/N nắng_nóng/N cực_đoan/A thiệt_hại/V kinh_tế/N và/C di_cư/N\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_corpus = io.open(\"./Data/gold.txt\", encoding=\"utf-8\").readlines()\n",
    "gold_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd538a24",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cb4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_n_grams('./Vocab/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab427fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "index = 0\n",
    "for word in sorted(vocab): \n",
    "    if word not in vocab_dict: \n",
    "        vocab_dict[word] = index  \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6826c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ vựng: 23800\n"
     ]
    }
   ],
   "source": [
    "print('Số lượng từ vựng:', len(vocab_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936bcca8",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c323b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(gold_corpus, train_size=0.8, random_state=23, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "520bdb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['những/D website/N được/V thiết_kế/V đẹp_mắt/A với/C bố_cục/N hài_hoà/A và/C tỉ_lệ/N cân_đối/A sẽ/R chiếm/V được/R thiện_cảm/N của/E người_dùng/N\\n',\n",
       " 'việc/N tối_ưu/V tốc_độ/N tải/V trang/N luôn/R là/V nhiệm_vụ/N được/V đặt/V lên/V hàng_đầu/N\\n',\n",
       " 'tiếng_anh/N của/E tôi/P rất/R kém/A vì_vậy/C tôi/P cần/V cải_thiện/V nhiều/A hơn/A\\n',\n",
       " 'cà_phê/N ở/E đây/P làm/V tôi/P phê/V tận/V nóc/N\\n',\n",
       " 'con_người/N chỉ/R đơn_giản/A là/V những/D cỗ_máy/N vô_cùng/R phức_tạp/A\\n',\n",
       " 'công_việc/N của/E tôi/P không/R hẳn/R là/V dễ/A nhưng/C dường_như/I tôi/P đang/R suy_nghĩ/V nhiều/A về/E nó/P\\n',\n",
       " 'người_dùng/N có_thể/R xem/V và/C chỉ/V rõ/A thông_tin/N nào/P được/V thu_thập/V để/E thực_thi/V 1_số/D chế_định/N về/E quyền/N riêng_tư/A\\n',\n",
       " 'tôi/P đang/R làm/V bài_tập/N gán/V nhãn/N từ_loại/N trong/E từ_điển/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " '1/M nghề/N cho/E chín/A còn/R hơn/A chín/M nghề/N\\n']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ffe253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab, data):\n",
    "    num_regex = re.compile(r'\\d+([.]\\d+)?')\n",
    "    words = []\n",
    "    words_pos = []\n",
    "    for line in data:\n",
    "        line_split = line.split()\n",
    "        words.append(\"<s>\")\n",
    "        words_pos.append((\"<s>\",\"<s>\"))\n",
    "        for index, word in enumerate(line_split):\n",
    "            w, pos = word.split('/')\n",
    "            if num_regex.fullmatch(w):\n",
    "                w = \"<digit>\"\n",
    "            words_pos.append((w, pos))\n",
    "            if w not in vocab:\n",
    "                w = '<unk>'\n",
    "            words.append(w)\n",
    "    return words, words_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e807d1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_words, train_words_pos = preprocess(vocab_dict, train)\n",
    "test_words, test_words_pos = preprocess(vocab_dict, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8521640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập train_gold: 611\n",
      "Số lượng từ trong tập test_gold: 186\n"
     ]
    }
   ],
   "source": [
    "print('Số lượng từ trong tập train_gold:', len(train_words))\n",
    "print('Số lượng từ trong tập test_gold:', len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fb06f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các từ không nằm trong vocabs: lâm_viên, nhìn_thấy, bàn_phím, ngón_tay, visual_designer, mọi_thứ, "
     ]
    }
   ],
   "source": [
    "print('Các từ không nằm trong vocabs', end=': ')\n",
    "for word, word_pos in zip(test_words, test_words_pos):\n",
    "    if word == '<unk>': \n",
    "        print(word_pos[0], end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815be67c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ce48dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_prob(word, tag, train_bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c208712a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionaries(data, vocab):\n",
    "    emission_counts = defaultdict(int)\n",
    "    transition_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    prev_tag = \"\"\n",
    "    for i, word_tag in enumerate(data):\n",
    "        word, tag = word_tag\n",
    "        if i == 0:\n",
    "            prev_tag = tag\n",
    "            continue\n",
    "        transition_counts[(prev_tag, tag)] += 1\n",
    "        emission_counts[(tag, word)] += 1\n",
    "        tag_counts[tag] += 1\n",
    "        prev_tag = tag\n",
    "    return transition_counts, emission_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97d14a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_counts, emission_counts, tag_counts = create_dictionaries(train_words_pos, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0548354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số nhãn: 11\n",
      "['<s>', 'A', 'C', 'D', 'E', 'I', 'M', 'N', 'P', 'R', 'V']\n"
     ]
    }
   ],
   "source": [
    "states = sorted(tag_counts.keys())\n",
    "print('Số nhãn:', len(states))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f1bcbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition examples: \n",
      "(('<s>', 'D'), 4)\n",
      "(('D', 'N'), 18)\n",
      "(('N', 'V'), 42)\n",
      "(('V', 'V'), 27)\n",
      "(('V', 'A'), 17)\n",
      "(('A', 'C'), 4)\n",
      "(('C', 'N'), 5)\n",
      "(('N', 'A'), 15)\n",
      "(('A', 'R'), 3)\n",
      "(('R', 'V'), 24)\n"
     ]
    }
   ],
   "source": [
    "print(\"Transition examples: \")\n",
    "for example in list(transition_counts.items())[:10]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c56c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission examples: \n",
      "(('D', 'những'), 10)\n",
      "(('N', 'website'), 1)\n",
      "(('V', 'được'), 6)\n",
      "(('V', 'thiết_kế'), 1)\n",
      "(('A', 'đẹp_mắt'), 1)\n",
      "(('C', 'với'), 1)\n",
      "(('N', 'bố_cục'), 1)\n",
      "(('A', 'hài_hoà'), 1)\n",
      "(('C', 'và'), 7)\n",
      "(('N', 'tỉ_lệ'), 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Emission examples: \")\n",
    "for example in list(emission_counts.items())[:10]:\n",
    "    print (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b72bf6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos(words_pos, emission_counts, vocab_dict, states):\n",
    "    num_correct = 0\n",
    "    all_words = set(emission_counts.keys())\n",
    "    \n",
    "    for word_pos in words_pos: \n",
    "        word, true_label = word_pos\n",
    "        count_final = 0\n",
    "        pos_final = ''\n",
    "        if word not in vocab_dict: \n",
    "            continue\n",
    "        \n",
    "        for pos in states:\n",
    "            if (pos, word) not in emission_counts: \n",
    "                continue\n",
    "            count = emission_counts[(pos, word)]\n",
    "            \n",
    "            if count > count_final:\n",
    "                count_final = count\n",
    "                pos_final = pos\n",
    "        if pos_final == true_label: num_correct += 1\n",
    "    accuracy = num_correct / len(words_pos)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e46137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập train: 0.9754500818330606\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(train_words_pos, emission_counts, vocab_dict, states)\n",
    "print('Độ chính xác trên tập train:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a07c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập test: 0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(test_words_pos, emission_counts, vocab_dict, states)\n",
    "print('Độ chính xác trên tập test:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913d8e94",
   "metadata": {},
   "source": [
    "### Hidden Markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be9530a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6c2d4",
   "metadata": {},
   "source": [
    "#### Transition matrix A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6c08b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    A = np.zeros((num_tags, num_tags))\n",
    "    trans_keys = set(transition_counts.keys())\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_tags):\n",
    "            count = 0\n",
    "            key = (all_tags[i], all_tags[j])\n",
    "            if key in transition_counts: \n",
    "                count = transition_counts[key]\n",
    "            count_prev_tag = tag_counts[all_tags[i]]\n",
    "            A[i, j] = (count + alpha) / (count_prev_tag + alpha * num_tags)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04ab097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc87e3f",
   "metadata": {},
   "source": [
    "#### Emission matrix B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0e3fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emission_matrix(alpha, tag_counts, emission_counts, vocabs):\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    num_tags = len(tag_counts)\n",
    "    num_words = len(vocabs)\n",
    "    \n",
    "    B = np.zeros((num_tags, num_words))\n",
    "    emis_keys = set(list(emission_counts.keys()))\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_words):\n",
    "            count = 0\n",
    "            key = (all_tags[i], vocabs[j])\n",
    "            if key in emission_counts.keys(): \n",
    "                count = emission_counts[key]\n",
    "            count_tag = tag_counts[all_tags[i]]\n",
    "            B[i, j] = (count + alpha) / (count_tag + alpha * num_words)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "18bc81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907eb047",
   "metadata": {},
   "source": [
    "#### Viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f8f682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([sublist[1:].tolist() for sublist in A])\n",
    "B = B[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e9c3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_initialize(states, tag_counts, A, B, corpus, vocab_dict):\n",
    "    num_tags = len(states)\n",
    "    s_idx = 0\n",
    "    \n",
    "    best_probs = np.zeros((num_tags, len(corpus)))\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype=int)\n",
    "    \n",
    "    for i in range(num_tags):\n",
    "        if A[s_idx, i - 1] == 0: best_probs[i, 0] = float('-inf')\n",
    "        else: \n",
    "            index = vocab_dict[corpus[0]]\n",
    "            # best_probs[i, 0] = math.log(A[s_idx, i]) + math.log(B[i, index])\n",
    "            best_probs[i, 0] = math.log(A[s_idx, i - 1]) + math.log(B[i - 1, index])\n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b54e1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs_train, best_paths_train = viterbi_initialize(states, tag_counts, A, B, train_words, vocab_dict)\n",
    "best_probs_test, best_paths_test = viterbi_initialize(states, tag_counts, A, B, test_words, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3568c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A, B, corpus, best_probs, best_paths, vocab_dict):\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for i in range(1, len(corpus)):         \n",
    "        for j in range(num_tags):\n",
    "            best_prob_i = float('-inf')\n",
    "            best_path_i = None\n",
    "            \n",
    "            for k in range(num_tags):\n",
    "                index = vocab_dict[corpus[i]]\n",
    "                # prob = best_probs[k, i - 1] + math.log(A[k, j]) + math.log(B[j, index])\n",
    "                prob = best_probs[k, i - 1] + math.log(A[k, j - 1]) + math.log(B[j - 1, index])\n",
    "\n",
    "                if prob > best_prob_i:\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "                    \n",
    "            best_probs[j, i] = best_prob_i\n",
    "            best_paths[j, i] = best_path_i\n",
    "            \n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd2f7521",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs_train, best_paths_train = viterbi_forward(A, B, train_words, best_probs_train, best_paths_train, vocab_dict)\n",
    "best_probs_test, best_paths_test = viterbi_forward(A, B, test_words, best_probs_test, best_paths_test, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d160b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_states = states\n",
    "new_states.remove(\"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a05e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, states):\n",
    "    m = best_paths.shape[1] \n",
    "    z = [None] * m\n",
    "    pred = [None] * m\n",
    "    \n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for k in range(num_tags):\n",
    "        if best_probs[k, m - 1] > best_prob_for_last_word:\n",
    "            best_prob_for_last_word = best_probs[k, m - 1]\n",
    "            z[m - 1] = k\n",
    "            \n",
    "    pred[m - 1] = states[z[m - 1]-1]\n",
    "    for i in range(m - 1, -1, -1):\n",
    "        z[i - 1] = best_paths[z[i], i]\n",
    "        pred[i - 1] = states[z[i - 1]-1]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cfeaeedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'đà_lạt', 'là', 'thành_phố', 'trực_thuộc', 'tỉnh', 'lâm_đồng', 'nằm', 'trên', 'cao_nguyên']\n",
      "['D', 'N', 'V', 'N', 'V', 'P', 'R', 'V', 'E', 'P']\n"
     ]
    }
   ],
   "source": [
    "train_pred = viterbi_backward(best_probs_train, best_paths_train, new_states)\n",
    "test_pred = viterbi_backward(best_probs_test, best_paths_test, new_states)\n",
    "# m = len(test_pred)\n",
    "\n",
    "# print(f'Dự đoán cho test_pred[0:{m - 1}]:')\n",
    "print(test_words[:10])\n",
    "print(test_pred[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c63a8ed",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bae9d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "đà_lạt/N là/V thành_phố/N trực_thuộc/V tỉnh/P lâm_đồng/R nằm/V trên/E cao_nguyên/P <unk>/R thuộc/V vùng/P tây_nguyên/R việt_nam/V \n",
      "song_song/R là/V <digit>/M cửa_sổ/N <digit>/M người/N ngồi/V trong/E cửa_sổ/P song_song/R \n",
      "nó/P có/V đầy_đủ/E các/D nhân_vật/N được/V phát_triển/V chuẩn/A và/C <digit>/M bối_cảnh/N trò_chơi/P vô_cùng/R sống_động/V \n",
      "nhưng/C đó/P là/V chuyện/P đã/R qua/V \n",
      "nếu_như/R là/V trước_đây/P chắc/V tôi/P sẽ/R sợ/V không/R muốn/V ai/P <unk>/V phần/N cơ_thể/V đó/P \n",
      "sau/N trận/C mưa_lũ/I lịch_sử/P đà_nẵng/R giá/V rau/P nhích/R lên/V chính_quyền/P cảnh_báo/R không/R lợi_dụng/V nâng/P giá/R \n",
      "gõ/P <unk>/R bằng/V <digit>/M <unk>/N sẽ/R giúp/V bạn/P có/V tốc_độ/N gõ/R nhanh/A hơn/A \n",
      "mỗi/D buổi/N chiều/N tôi/P thường/R dành/V thời_gian/N để/E tập/P gym/V hoặc/P đá/R bóng/A và/C tôi/P đang/R cố_gắng/V để/E duy_trì/V nó/P \n",
      "sứ_mệnh/V của/E <unk>/P là/V mang/V đến/E những/D trải_nghiệm/N thú_vị/A và/C độc_đáo/V cho/E người_dùng/N \n",
      "điều/N quan_trọng/R là/V bạn/P phải/V có/V mục_tiêu/P rõ_ràng/V và/C cụ_thể/V cho/E tương_lai/N của/E mình/P \n",
      "tôi/P thích/R đi/V du_lịch/P bằng/R xe_máy/V bởi/E như_vậy/P có_thể/R tận_hưởng/V <unk>/P tốt/A hơn/A \n",
      "chuối/R có/V chứa/P rất/R nhiều/A chất/V dinh_dưỡng/P cần_thiết/R cho/V cơ_thể/P \n",
      "nếu/R để_ý/V bạn/P sẽ/R thấy/V chuyện/P đôi_lứa/R bên/V nhau/P cũng/R chẳng/R khác/V <digit>/M cuộc/N khiêu_vũ/R là/V mấy/V "
     ]
    }
   ],
   "source": [
    "for word, tag in zip(test_words, test_pred):\n",
    "    if word == '<s>': \n",
    "        print()\n",
    "    else: \n",
    "        print(f'{word}/{tag}', end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa4b4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def report(pred, gold):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for prediction, word_tag in zip(pred, gold):\n",
    "        word, tag = word_tag\n",
    "        y_pred.append(prediction)\n",
    "        y_true.append(tag)\n",
    "        \n",
    "    print(classification_report(y_pred, y_true))\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bb67ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập train:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <s>       0.00      0.00      0.00         0\n",
      "           A       1.00      0.96      0.98        53\n",
      "           C       0.94      0.83      0.88        18\n",
      "           D       1.00      0.86      0.92        21\n",
      "           E       0.98      0.76      0.86        72\n",
      "           I       1.00      1.00      1.00         2\n",
      "           M       1.00      0.63      0.77        19\n",
      "           N       0.98      0.99      0.98       185\n",
      "           P       0.97      0.90      0.94        42\n",
      "           R       0.98      0.93      0.95        45\n",
      "           V       0.99      0.88      0.93       154\n",
      "\n",
      "    accuracy                           0.90       611\n",
      "   macro avg       0.89      0.80      0.84       611\n",
      "weighted avg       0.98      0.90      0.94       611\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập train:\\n')\n",
    "y_pred, y_true_train = report(train_pred, train_words_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31ec697c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <s>       0.00      0.00      0.00         0\n",
      "           A       0.41      0.78      0.54         9\n",
      "           C       0.56      0.71      0.63         7\n",
      "           D       1.00      0.75      0.86         4\n",
      "           E       0.75      0.75      0.75        12\n",
      "           I       0.00      0.00      0.00         1\n",
      "           M       1.00      1.00      1.00         5\n",
      "           N       0.34      1.00      0.51        18\n",
      "           P       1.00      0.33      0.49        40\n",
      "           R       1.00      0.36      0.53        36\n",
      "           V       0.77      0.67      0.71        54\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59       186\n",
      "   macro avg       0.57      0.53      0.50       186\n",
      "weighted avg       0.80      0.59      0.61       186\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập test:\\n')\n",
    "y_pred, y_true_test = report(test_pred, test_words_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12942ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"tôi chơi đá bóng\"\n",
    "tokens = longest_matching(test_sentence, bi_grams, tri_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "750381ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tôi', 'chơi', 'đá', 'bóng']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "47006ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs, paths = viterbi_initialize(states, tag_counts, A, B, tokens, vocab_dict)\n",
    "pred = viterbi_backward(probs, paths, new_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d27e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi/V chơi/V đá/V bóng/V "
     ]
    }
   ],
   "source": [
    "for word, tag in zip(tokens, pred):\n",
    "  print(f'{word}/{tag}', end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
