{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố/N washington/N có/V 1/M kiến_trúc/N rất/R đa_dạng/A\\n',\n",
       " 'tuy_nhiên/C vì/C gặp/V nhiều/A khó_khăn/N trong/E cuộc_sống/N ông/N dần/R trở_nên/V khó_tính/A\\n',\n",
       " 'khí_hậu/N hồng_kông/N thuộc/V kiểu/N cận_nhiệt_đới/N và/C chịu/V ảnh_hưởng/V của/E gió_mùa/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " 'đà_lạt/N là/V thành_phố/N trực_thuộc/V tỉnh/N lâm_đồng/N nằm/V trên/E cao_nguyên/N lâm_viên/N thuộc/V vùng/N tây_nguyên/N việt_nam/N\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_corpus = io.open(\"./Data/gold.txt\", encoding=\"utf-8\").readlines()\n",
    "gold_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format(data):\n",
    "  formated = []\n",
    "  for line in data:\n",
    "    sentence = []\n",
    "    words_tags = line.split()\n",
    "    for word_tag in words_tags:\n",
    "      word, tag = word_tag.split(\"/\")\n",
    "      sentence.append((word,tag))\n",
    "    formated.append(sentence)\n",
    "  return formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = format(gold_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, train_size=0.8, random_state=23, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Vocab/vocab.txt', encoding='utf8') as f:\n",
    "  vocab = f.read().splitlines() \n",
    "vocab_dict = {}\n",
    "index = 0\n",
    "for word in sorted(vocab): \n",
    "    if word not in vocab_dict: \n",
    "        vocab_dict[word] = index  \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, vocab_dict):\n",
    "  all_tags = []\n",
    "  all_words = []\n",
    "  tagged_words = []\n",
    "  for sent in data:\n",
    "    all_tags.append(\"<s>\")\n",
    "    for word, tag in sent:\n",
    "        all_tags.append(tag)\n",
    "        if word not in vocab_dict:\n",
    "          word = \"<unk>\"\n",
    "        all_words.append(word)\n",
    "        tagged_words.append((word, tag))\n",
    "  return all_tags, all_words, tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags, train_words, train_tagged_words = preprocess(train_set, vocab_dict)\n",
    "test_tags, test_words, test_tagged_words = preprocess(test_set, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'D', 'N', 'V', 'V']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('những', 'D'),\n",
       " ('website', 'N'),\n",
       " ('được', 'V'),\n",
       " ('thiết_kế', 'V'),\n",
       " ('đẹp_mắt', 'A')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transition count\n",
    "def transition_count(all_tags):\n",
    "  transition_count = defaultdict(int)\n",
    "  prev_tag = all_tags[0]\n",
    "  for i in range(1, len(all_tags)):\n",
    "    tag = all_tags[i]\n",
    "    transition_count[(prev_tag, tag)] += 1\n",
    "    prev_tag = tag\n",
    "  return transition_count\n",
    "transition = transition_count(train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission count\n",
    "def emission_count(tagged_words):\n",
    "  emission_count = defaultdict(int)\n",
    "  for tagged_word in tagged_words:\n",
    "    word, tag = tagged_word\n",
    "    emission_count[(tag, word)] += 1\n",
    "  return emission_count\n",
    "emission = emission_count(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag count\n",
    "def tag_count(all_tags):\n",
    "  tag_count = defaultdict(int)\n",
    "  for tag in all_tags:\n",
    "    tag_count[tag] += 1\n",
    "  return tag_count\n",
    "tags = tag_count(train_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [k for k, _ in sorted(tags.items(), key=lambda item: item[1], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'V', 'E', 'A', '<s>', 'R', 'P', 'D', 'C', 'M', 'I']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with emission count\n",
    "def predict_pos(tagged_words, emission, vocab, states):\n",
    "  num_correct = 0\n",
    "  valid_states = states.copy()\n",
    "  valid_states.remove(\"<s>\")\n",
    "  for tagged_word in tagged_words:\n",
    "    word, true_tag = tagged_word\n",
    "    count_final = 0 \n",
    "    count = 0\n",
    "    tag_final = ''\n",
    "\n",
    "    for tag in valid_states:\n",
    "      if word not in vocab_dict:\n",
    "        tag_final = valid_states[0]\n",
    "        break\n",
    "      if (tag, word) not in emission:\n",
    "        continue\n",
    "      count = emission[(tag, word)]\n",
    "\n",
    "      if count > count_final:\n",
    "        count_final = count\n",
    "        tag_final = tag\n",
    "    if tag_final == true_tag:\n",
    "      num_correct += 1\n",
    "  accuracy = num_correct / len(tagged_words)\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập train: 0.9733096085409253\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(train_tagged_words, emission, vocab_dict, states)\n",
    "print('Độ chính xác trên tập train:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ chính xác trên tập test: 0.4624277456647399\n"
     ]
    }
   ],
   "source": [
    "accuracy = predict_pos(test_tagged_words, emission, vocab_dict, states)\n",
    "print('Độ chính xác trên tập test:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hidden markov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_matrix(alpha, transition, states, tags):\n",
    "  valid_states = states.copy()\n",
    "  valid_states.remove(\"<s>\")\n",
    "  len_tags = len(valid_states)\n",
    "  A = np.zeros((len_tags, len_tags))\n",
    "  \n",
    "  for i in range(len_tags):\n",
    "    for j in range(len_tags):\n",
    "      count = 0\n",
    "      if (valid_states[i], valid_states[j]) in transition:\n",
    "        count = transition[(valid_states[i], valid_states[j])]\n",
    "      \n",
    "      count_prev_tag = tags[valid_states[i]]\n",
    "      A[i, j] = (count + alpha) / (count_prev_tag + alpha * len_tags)\n",
    "  return A\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.000001\n",
    "A = transition_matrix(alpha, transition, states, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emission_matrix(alpha, emission, vocab_dict, states, tags):\n",
    "  vocab = [v for v in vocab_dict]\n",
    "  valid_states = states.copy()\n",
    "  valid_states.remove(\"<s>\")\n",
    "  len_tags = len(valid_states)\n",
    "  len_vocab = len(vocab)\n",
    "\n",
    "  B = np.zeros((len_tags, len_vocab))\n",
    "  \n",
    "  for i in range(len_tags):\n",
    "    for j in range(len_vocab):\n",
    "      count = 0\n",
    "      if (valid_states[i], vocab[j]) in emission:\n",
    "        count = emission[(valid_states[i], vocab[j])]\n",
    "      \n",
    "      count_tag = tags[valid_states[i]]\n",
    "      B[i,j] = (count + alpha) / (count_tag + alpha * len_vocab)\n",
    "  return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = emission_matrix(alpha, emission,vocab_dict, states, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_initialize(states, tags, A, B, corpus, vocab_dict):\n",
    "  valid_states = states.copy()\n",
    "  valid_states.remove(\"<s>\")\n",
    "  len_tags = len(valid_states)\n",
    "\n",
    "  best_probs = np.zeros((len_tags, len(corpus)))\n",
    "  best_paths = np.zeros((len_tags, len(corpus)), dtype=int)\n",
    "\n",
    "  for i in range(len_tags):\n",
    "      index = vocab_dict[corpus[0]]\n",
    "      best_probs[i,0] = math.log(A[0, i]) + math.log(B[i, index])\n",
    "  return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs_train, best_paths_train = viterbi_initialize(states, train_tags, A, B, train_words, vocab_dict)\n",
    "best_probs_test, best_paths_test = viterbi_initialize(states, tags, A, B, test_words, vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_forward(A, B, corpus, best_probs, best_paths, vocabs_dict):\n",
    "    num_tags = best_probs.shape[0]\n",
    "    for i in range(1, len(corpus)): \n",
    "        # if i % 5000 == 0: print(f'Processed {i} words...')\n",
    "        for j in range(num_tags):\n",
    "            best_prob_i = float('-inf')\n",
    "            best_path_i = None\n",
    "            for k in range(num_tags):\n",
    "                index = vocabs_dict[corpus[i]]\n",
    "                prob = best_probs[k, i - 1] + math.log(A[k, j]) + math.log(B[j, index])\n",
    "                # prob = best_probs[k, i - 1] + math.log(A[k, j - 1]) + math.log(B[j - 1, index])\n",
    "\n",
    "                if prob > best_prob_i:\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "                    \n",
    "            best_probs[j, i] = best_prob_i\n",
    "            best_paths[j, i] = best_path_i\n",
    "            \n",
    "    return best_probs, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_probs_train[0, 1]: -11.051450965573057\n",
      "best_paths_train[0, 4]: 1\n"
     ]
    }
   ],
   "source": [
    "best_probs_train, best_paths_train = viterbi_forward(A, B, train_words, best_probs_train, best_paths_train, vocab_dict)\n",
    "best_probs_test, best_paths_test = viterbi_forward(A, B, test_words, best_probs_test, best_paths_test, vocab_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backward(best_probs, best_paths, corpus, states):\n",
    "    valid_states = states.copy()\n",
    "    valid_states.remove(\"<s>\")\n",
    "    m = best_paths.shape[1] \n",
    "    z = [None] * m\n",
    "    pred = [None] * m\n",
    "    \n",
    "    best_prob_for_last_word = float('-inf')\n",
    "    num_tags = best_probs.shape[0]\n",
    "    \n",
    "    for k in range(num_tags):\n",
    "        if best_probs[k, m - 1] > best_prob_for_last_word:\n",
    "            best_prob_for_last_word = best_probs[k, m - 1]\n",
    "            z[m - 1] = k\n",
    "            \n",
    "    pred[m - 1] = valid_states[z[m - 1]]\n",
    "    for i in range(m - 1, -1, -1):\n",
    "        z[i - 1] = best_paths[z[i], i]\n",
    "        pred[i - 1] = valid_states[z[i - 1]]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['đà_lạt', 'là', 'thành_phố', 'trực_thuộc', 'tỉnh', 'lâm_đồng', 'nằm', 'trên', 'cao_nguyên', '<unk>']\n",
      "['N', 'V', 'N', 'C', 'I', 'P', 'V', 'E', 'P', 'R']\n"
     ]
    }
   ],
   "source": [
    "train_pred = viterbi_backward(best_probs_train, best_paths_train, train_words, states)\n",
    "test_pred = viterbi_backward(best_probs_test, best_paths_test, test_words, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "đà_lạt/N là/V thành_phố/N trực_thuộc/C tỉnh/I lâm_đồng/P nằm/V trên/E cao_nguyên/P <unk>/R thuộc/V vùng/A tây_nguyên/C việt_nam/I \n",
      "song_song/P là/V 2/I cửa_sổ/P 2/V người/N ngồi/V trong/E cửa_sổ/V song_song/I \n",
      "nó/P có/V đầy_đủ/E các/D nhân_vật/N được/V phát_triển/V chuẩn/A và/C 1/M bối_cảnh/N trò_chơi/P vô_cùng/R sống_động/A \n",
      "nhưng/C đó/P là/V chuyện/I đã/V qua/I \n",
      "nếu_như/P là/V trước_đây/C chắc/I tôi/P sẽ/R sợ/R không/R muốn/A ai/C <unk>/D phần/N cơ_thể/E đó/P \n",
      "sau/N trận/C mưa_lũ/I lịch_sử/P đà_nẵng/C giá/I rau/P nhích/R lên/V chính_quyền/I cảnh_báo/P không/R lợi_dụng/A nâng/C giá/I \n",
      "gõ/V <unk>/D bằng/N 5/E <unk>/P sẽ/R giúp/V bạn/P có/V tốc_độ/N gõ/R nhanh/A hơn/A \n",
      "mỗi/D buổi/N chiều/N tôi/P thường/R dành/V thời_gian/N để/E tập/D gym/N hoặc/C đá/I bóng/P và/C tôi/P đang/R cố_gắng/V để/E duy_trì/N nó/P \n",
      "sứ_mệnh/V của/E <unk>/P là/V mang/V đến/E những/D trải_nghiệm/N thú_vị/A và/C độc_đáo/I cho/V người_dùng/N \n",
      "điều/N quan_trọng/R là/V bạn/P phải/V có/V mục_tiêu/I rõ_ràng/P và/C cụ_thể/I cho/V tương_lai/N của/E mình/P \n",
      "tôi/R thích/A đi/C du_lịch/I bằng/P xe_máy/V bởi/E như_vậy/P có_thể/R tận_hưởng/A <unk>/M tốt/N hơn/A \n",
      "chuối/C có/V chứa/P rất/R nhiều/A chất/V dinh_dưỡng/I cần_thiết/P cho/V cơ_thể/A \n",
      "nếu/C để_ý/I bạn/P sẽ/R thấy/A chuyện/C đôi_lứa/C bên/I nhau/P cũng/R chẳng/R khác/A 1/M cuộc/N khiêu_vũ/R là/V mấy/N "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for tag in test_tags:\n",
    "  if tag == \"<s>\":\n",
    "    print()\n",
    "    continue\n",
    "  else:\n",
    "    print(test_words[i], end=\"/\")\n",
    "    print(test_pred[i], end=\" \")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def report(pred, gold):\n",
    "    y_pred = pred\n",
    "    y_true = [t for t in gold if t != \"<s>\"]\n",
    "    \n",
    "    print(classification_report(y_pred, y_true))\n",
    "    return y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập train:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00        51\n",
      "           C       0.94      0.88      0.91        17\n",
      "           D       1.00      1.00      1.00        18\n",
      "           E       0.98      0.95      0.96        58\n",
      "           I       1.00      1.00      1.00         2\n",
      "           M       1.00      1.00      1.00        12\n",
      "           N       0.98      1.00      0.99       184\n",
      "           P       0.97      1.00      0.99        38\n",
      "           R       0.98      0.95      0.97        44\n",
      "           V       0.98      0.98      0.98       138\n",
      "\n",
      "    accuracy                           0.98       562\n",
      "   macro avg       0.98      0.98      0.98       562\n",
      "weighted avg       0.98      0.98      0.98       562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập train:\\n')\n",
    "y_pred, y_true_train = report(train_pred, train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập test:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.47      0.53      0.50        15\n",
      "           C       0.78      0.39      0.52        18\n",
      "           D       1.00      0.50      0.67         6\n",
      "           E       0.58      0.64      0.61        11\n",
      "           I       0.00      0.00      0.00        19\n",
      "           M       0.40      0.67      0.50         3\n",
      "           N       0.30      0.76      0.43        21\n",
      "           P       0.85      0.38      0.52        29\n",
      "           R       0.92      0.63      0.75        19\n",
      "           V       0.49      0.72      0.58        32\n",
      "           X       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51       173\n",
      "   macro avg       0.53      0.47      0.46       173\n",
      "weighted avg       0.57      0.51      0.50       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Kết quả của mô hình Hidden Markov kết hợp thuật toán Viterbi trên tập test:\\n')\n",
    "y_pred, y_true_test = report(test_pred, test_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [\"vì\", \"nó\", \"rất\", \"phức_tạp\", \"nên\",\"tôi\",\"đã\",\"chú_ý\"]\n",
    "best_probs_sent, best_paths_sent = viterbi_initialize(states, tags, A, B, sentence, vocab_dict)\n",
    "best_probs_sent, best_paths_sent = viterbi_forward(A, B, sentence, best_probs_sent, best_paths_sent, vocab_dict)\n",
    "sent_pred = viterbi_backward(best_probs_sent, best_paths_sent, test_words, states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vì/E nó/P rất/R phức_tạp/A nên/C tôi/P đã/R chú_ý/N "
     ]
    }
   ],
   "source": [
    "for word, tag in zip(sentence,sent_pred):\n",
    "  print(word + \"/\" + tag, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
