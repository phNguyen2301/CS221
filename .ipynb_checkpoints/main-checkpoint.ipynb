{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679d5f32",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aebffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "data_path = \"./Data\"\n",
    "file_name = os.listdir(data_path)\n",
    "file_path = [os.path.join(data_path, name) for name in file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509e7489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Data\\\\easy_sentence.txt', './Data\\\\gold.txt', './Data\\\\gold_sentence.txt', './Data\\\\hard_sentence.txt']\n"
     ]
    }
   ],
   "source": [
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36a1b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_sentence = io.open(\"./Data/easy_sentence.txt\", encoding=\"utf-8\").readlines()\n",
    "hard_sentence = io.open(\"./Data/hard_sentence.txt\", encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f69435",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sentence = easy_sentence\n",
    "data_sentence.extend(hard_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddf98592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành phố washington có một kiến trúc rất đa dạng\\n',\n",
       " 'tuy nhiên vì gặp nhiều khó khăn trong cuộc sống ông dần trở nên khó tính\\n',\n",
       " 'khí hậu hồng kông thuộc kiểu cận nhiệt đới và chịu ảnh hưởng của gió mùa\\n',\n",
       " 'khoảng hơn 70 bề mặt trái đất được bao phủ bởi các đại dương nước mặn phần còn lại là các lục địa và các đảo\\n',\n",
       " 'đà lạt là thành phố trực thuộc tỉnh lâm đồng nằm trên cao nguyên lâm viên thuộc vùng tây nguyên việt nam\\n',\n",
       " 'đổi đất đai lấy hạ tầng là một trong những việc phải làm trong bối cảnh hiện nay\\n',\n",
       " 'cuối tuần trước tôi về quê vì gia đình có đám\\n',\n",
       " 'những cơn gió căng tràng vi vu khắp núi rừng đà lạt khiến những quả hồng uống no nê những giọt sương mờ\\n',\n",
       " 'nhưng đó là chuyện đã qua\\n',\n",
       " 'biến đổi khí hậu đe doạ đến con người khi nó gây bất an lương thực khan hiếm nước lũ lụt nắng nóng cực đoan thiệt hại kinh tế và di cư\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sentence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00963a2",
   "metadata": {},
   "source": [
    "# Tách từ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82f1b2",
   "metadata": {},
   "source": [
    "## Longest Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e640188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata as ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0963637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllablize(sentence):\n",
    "    word = '\\w+'\n",
    "    non_word = '[^\\w\\s]'\n",
    "    digits = '\\d+([\\.,_]\\d+)+'\n",
    "    \n",
    "    patterns = []\n",
    "    patterns.extend([word, non_word, digits])\n",
    "    patterns = f\"({'|'.join(patterns)})\"\n",
    "    \n",
    "    sentence = ud.normalize('NFC', sentence)\n",
    "    tokens = re.findall(patterns, sentence, re.UNICODE)\n",
    "    return [token[0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8327241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_grams(path):\n",
    "    with open(path, encoding='utf8') as f:\n",
    "        words = f.read().splitlines() \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "458a0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_matching(sentence, bi_grams, tri_grams):\n",
    "    syllables = syllablize(sentence)\n",
    "    syl_len = len(syllables)\n",
    "    \n",
    "    curr_id = 0\n",
    "    word_list = []\n",
    "    done = False\n",
    "    \n",
    "    while (curr_id < syl_len) and (not done):\n",
    "        curr_word = syllables[curr_id]\n",
    "        if curr_id >= syl_len - 1:\n",
    "            word_list.append(curr_word)\n",
    "            done = True\n",
    "        else:\n",
    "            next_word = syllables[curr_id + 1]\n",
    "            pair_word = ' '.join([curr_word.lower(), next_word.lower()])\n",
    "            if curr_id >= (syl_len - 2):\n",
    "                if pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "            else:\n",
    "                next_next_word = syllables[curr_id + 2]\n",
    "                triple_word = ' '.join([pair_word, next_next_word.lower()])\n",
    "                if triple_word in tri_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word, next_next_word]))\n",
    "                    curr_id += 3\n",
    "                elif pair_word in bi_grams:\n",
    "                    word_list.append('_'.join([curr_word, next_word]))\n",
    "                    curr_id += 2\n",
    "                else:\n",
    "                    word_list.append(curr_word)\n",
    "                    curr_id += 1\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6439ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_grams = load_n_grams('./Vocab/vocab_bi_gram.txt')\n",
    "tri_grams = load_n_grams('./Vocab/vocab_tri_gram.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e883a998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận nhiệt_đới và chịu ảnh_hưởng của gió mùa']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Token/longest_matching_tokens.txt', 'w', encoding='utf-8') as f:\n",
    "    longest_matching_sentences = []\n",
    "    for sentence in data_sentence:\n",
    "        word_list = longest_matching(sentence, bi_grams, tri_grams)\n",
    "        longest_matching_sentences.append(' '.join(word_list))\n",
    "        f.write(' '.join(word_list) + '\\n')\n",
    "longest_matching_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97b540c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching: 224\n"
     ]
    }
   ],
   "source": [
    "count_longest_matching_compounds = 0\n",
    "for sentence in longest_matching_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_longest_matching_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching:', count_longest_matching_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f0b36",
   "metadata": {},
   "source": [
    "## VnCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5029bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import py_vncorenlp\n",
    "model = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\", \"pos\"], save_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d9b1ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận_nhiệt_đới và chịu ảnh_hưởng của gió_mùa']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('Token/vncore_tokens.txt', 'w', encoding='utf-8') as f:\n",
    "    vncore_sentences = []\n",
    "    for sentence in data_sentence:\n",
    "        words = model.word_segment(sentence)[0]\n",
    "        vncore_sentences.append(words)\n",
    "        f.write(words + '\\n')\n",
    "vncore_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4065fd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ bằng thư viện VnCoreNLP: 231\n"
     ]
    }
   ],
   "source": [
    "count_vncore_compounds = 0\n",
    "for sentence in vncore_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_vncore_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ bằng thư viện VnCoreNLP:', count_vncore_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5be61b",
   "metadata": {},
   "source": [
    "## Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69e407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_sentence = io.open(\"./Data/gold_sentence.txt\", encoding=\"utf-8\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a8455dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố washington có một kiến_trúc rất đa_dạng',\n",
       " 'tuy_nhiên vì gặp nhiều khó_khăn trong cuộc_sống ông dần trở_nên khó_tính',\n",
       " 'khí_hậu hồng_kông thuộc kiểu cận_nhiệt_đới và chịu ảnh_hưởng của gió_mùa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_tokenize_sentences = []\n",
    "for sentence in gold_sentence:\n",
    "    if sentence != '\\n': \n",
    "        manual_tokenize_sentences.append(sentence.strip())\n",
    "manual_tokenize_sentences[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e83360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ ghép khi tách từ thủ công: 256\n"
     ]
    }
   ],
   "source": [
    "count_manual_tokenize_compounds = 0\n",
    "for sentence in manual_tokenize_sentences:\n",
    "    for word in sentence.split():\n",
    "        if '_' in word: count_manual_tokenize_compounds += 1\n",
    "print('Số lượng từ ghép khi tách từ thủ công:', count_manual_tokenize_compounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e8113",
   "metadata": {},
   "source": [
    "## Đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecc06e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76b4143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct_words(pred, source, n_grams=3):\n",
    "    pred_words = pred.split()\n",
    "    source_words = source.split()\n",
    "    \n",
    "    total_true, tp = 0, 0\n",
    "    total_errors, fp = 0, 0\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < len(pred_words):\n",
    "        if pred_words[idx] not in source_words[idx:(idx + n_grams)]: \n",
    "            if '_' in pred_words[idx]: fp += 1\n",
    "            del pred_words[idx]\n",
    "            total_errors += 1\n",
    "        else: idx += 1\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < len(source_words):\n",
    "        if source_words[idx] not in pred_words[idx:(idx + n_grams)]: \n",
    "            del source_words[idx]\n",
    "        else: idx += 1\n",
    "    \n",
    "    if len(pred_words) < len(source_words): words = pred_words\n",
    "    else: words = source_words\n",
    "    \n",
    "    for idx in range (len(words)):\n",
    "        if pred_words[idx] == source_words[idx]:\n",
    "            if '_' in pred_words[idx]: tp += 1 \n",
    "            total_true += 1\n",
    "                    \n",
    "    return total_true, total_errors, tp, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81f2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_evaluation(pred, source, n_grams=3):\n",
    "    total_true = 0\n",
    "    total_errors = 0\n",
    "    total_words = 0\n",
    "    \n",
    "    pred_tp = 0\n",
    "    pred_fp = 0\n",
    "    \n",
    "    for pred_sentence, source_sentence in zip(pred, source):\n",
    "        total_words += len(source_sentence.split())\n",
    "        if pred_sentence != source_sentence:\n",
    "            true, error, tp, fp = count_correct_words(pred_sentence, source_sentence, n_grams)\n",
    "            total_true += true \n",
    "            total_errors += error\n",
    "            pred_tp += tp\n",
    "            pred_fp += fp\n",
    "        else:\n",
    "            for word in source_sentence.split():\n",
    "                if '_' in word:\n",
    "                    pred_tp += 1\n",
    "                total_true += 1\n",
    "                    \n",
    "    accuracy = total_true / total_words\n",
    "    precision = pred_tp / (pred_tp + pred_fp)\n",
    "    recall = pred_tp / count_manual_tokenize_compounds\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return {\n",
    "        'Accuracy': accuracy, \n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1': f1,\n",
    "        'True Positive': pred_tp, \n",
    "        'False Positive': pred_fp,\n",
    "        'Total True': total_true, \n",
    "        'Total Errors': total_errors\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2206c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longest Matching</th>\n",
       "      <th>VnCoreNLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.943723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.832031</td>\n",
       "      <td>0.851562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.8875</td>\n",
       "      <td>0.895277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>213</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive</th>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total True</th>\n",
       "      <td>665</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Errors</th>\n",
       "      <td>99</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Longest Matching VnCoreNLP\n",
       "Accuracy               0.904762  0.914286\n",
       "Precision              0.950893  0.943723\n",
       "Recall                 0.832031  0.851562\n",
       "F1                       0.8875  0.895277\n",
       "True Positive               213       218\n",
       "False Positive               11        13\n",
       "Total True                  665       672\n",
       "Total Errors                 99        81"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_matching_evaluation = tokenize_evaluation(longest_matching_sentences, manual_tokenize_sentences)\n",
    "vncore_evaluation = tokenize_evaluation(vncore_sentences, manual_tokenize_sentences)\n",
    "pd.DataFrame(\n",
    "    [longest_matching_evaluation, vncore_evaluation], \n",
    "    index = ['Longest Matching', 'VnCoreNLP']\n",
    ").astype(object).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69df03",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e541d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f2d939e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thành_phố/N washington/N có/V một/M kiến_trúc/N rất/R đa_dạng/A\\n',\n",
       " 'tuy_nhiên/C vì/C gặp/V nhiều/A khó_khăn/N trong/E cuộc_sống/N ông/N dần/R trở_nên/V khó_tính/A\\n',\n",
       " 'khí_hậu/N hồng_kông/N thuộc/V kiểu/N cận_nhiệt_đới/N và/C chịu/V ảnh_hưởng/V của/E gió_mùa/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " 'đà_lạt/N là/V thành_phố/N trực_thuộc/V tỉnh/N lâm_đồng/N nằm/V trên/E cao_nguyên/N lâm_viên/N thuộc/V vùng/N tây_nguyên/N việt_nam/N\\n',\n",
       " 'đổi/V đất_đai/N lấy/V hạ_tầng/N là/V một/M trong/E những/D việc/N phải/V làm/V trong/E bối_cảnh/N hiện_nay/N\\n',\n",
       " 'cuối/N tuần/N trước/N tôi/P về/V quê/N vì/E gia_đình/N có/V đám/N\\n',\n",
       " 'những/D cơn_gió/N căng_tràng/A vi_vu/V khắp/A núi_rừng/N đà_lạt/N khiến/V những/D quả/N hồng/N uống/V no_nê/A những/D giọt_sương/N mờ/A\\n',\n",
       " 'nhưng/C đó/P là/V chuyện/N đã/R qua/V\\n',\n",
       " 'biến_đổi/N khí_hậu/N đe_doạ/V đến/E con_người/N khi/C nó/P gây/V bất_an/A lương_thực/N khan_hiếm/A nước/N lũ_lụt/N nắng_nóng/N cực_đoan/A thiệt_hại/V kinh_tế/N và/C di_cư/N\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_corpus = io.open(\"./Data/gold.txt\", encoding=\"utf-8\").readlines()\n",
    "gold_corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfce4b",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2aa0224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(gold_corpus, train_size=0.8, random_state=23, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520bdb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['những/D website/N được/V thiết_kế/V đẹp_mắt/A với/C bố_cục/N hài_hoà/A và/C tỉ_lệ/N cân_đối/A sẽ/R chiếm/V được/R thiện_cảm/N của/E người_dùng/N\\n',\n",
       " 'việc/N tối_ưu/V tốc_độ/N tải/V trang/N luôn/R là/V nhiệm_vụ/N được/V đặt/V lên/V hàng_đầu/N\\n',\n",
       " 'tiếng_anh/N của/E tôi/P rất/R kém/A vì_vậy/C tôi/P cần/V cải_thiện/V nhiều/A hơn/A\\n',\n",
       " 'cà_phê/N ở/E đây/P làm/V tôi/P phê/V tận/V nóc/N\\n',\n",
       " 'con_người/N chỉ/R đơn_giản/A là/V những/D cỗ_máy/N vô_cùng/R phức_tạp/A\\n',\n",
       " 'công_việc/N của/E tôi/P không/R hẳn/R là/V dễ/A nhưng/C dường_như/I tôi/P đang/R suy_nghĩ/V nhiều/A về/E nó/P\\n',\n",
       " 'người_dùng/N có_thể/R xem/V và/C chỉ/V rõ/A thông_tin/N nào/P được/V thu_thập/V để/E thực_thi/V một_số/D chế_định/N về/E quyền/N riêng_tư/A\\n',\n",
       " 'tôi/P đang/R làm/V bài_tập/N gán/V nhãn/N từ_loại/N trong/E từ_điển/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " 'một/M nghề/N cho/E chín/A còn/R hơn/A chín/M nghề/N\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5fec14",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1017d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = load_n_grams('./Vocab/vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42a345a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "index = 0\n",
    "for word in sorted(vocab): \n",
    "    if word not in vocab_dict: \n",
    "        vocab_dict[word] = index  \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "876aedb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ vựng: 23800\n"
     ]
    }
   ],
   "source": [
    "print('Số lượng từ vựng:', len(vocab_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e955f1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['những/D website/N được/V thiết_kế/V đẹp_mắt/A với/C bố_cục/N hài_hoà/A và/C tỉ_lệ/N cân_đối/A sẽ/R chiếm/V được/R thiện_cảm/N của/E người_dùng/N\\n',\n",
       " 'việc/N tối_ưu/V tốc_độ/N tải/V trang/N luôn/R là/V nhiệm_vụ/N được/V đặt/V lên/V hàng_đầu/N\\n',\n",
       " 'tiếng_anh/N của/E tôi/P rất/R kém/A vì_vậy/C tôi/P cần/V cải_thiện/V nhiều/A hơn/A\\n',\n",
       " 'cà_phê/N ở/E đây/P làm/V tôi/P phê/V tận/V nóc/N\\n',\n",
       " 'con_người/N chỉ/R đơn_giản/A là/V những/D cỗ_máy/N vô_cùng/R phức_tạp/A\\n',\n",
       " 'công_việc/N của/E tôi/P không/R hẳn/R là/V dễ/A nhưng/C dường_như/I tôi/P đang/R suy_nghĩ/V nhiều/A về/E nó/P\\n',\n",
       " 'người_dùng/N có_thể/R xem/V và/C chỉ/V rõ/A thông_tin/N nào/P được/V thu_thập/V để/E thực_thi/V một_số/D chế_định/N về/E quyền/N riêng_tư/A\\n',\n",
       " 'tôi/P đang/R làm/V bài_tập/N gán/V nhãn/N từ_loại/N trong/E từ_điển/N\\n',\n",
       " 'khoảng/A hơn/A 70/M bề_mặt/N trái_đất/N được/V bao_phủ/V bởi/E các/D đại_dương/N nước_mặn/N phần/N còn_lại/V là/V các/D lục_địa/N và/C các/D đảo/N\\n',\n",
       " 'một/M nghề/N cho/E chín/A còn/R hơn/A chín/M nghề/N\\n']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "421c5243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(vocab, data):\n",
    "    num_regex = re.compile(r'\\d+([.]\\d+)?')\n",
    "    result = []\n",
    "    for line in data:\n",
    "        line_split = line.split()\n",
    "        result.append(\"<n>\",\"<s>\")\n",
    "        for index, word in enumerate(line_split):\n",
    "            w, pos = word.split('/')\n",
    "            if num_regex.fullmatch(w):\n",
    "                w = \"<digit>\"\n",
    "            if w not in vocab:\n",
    "                w = '<unk>'\n",
    "            result.append(w, pos)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96c81bfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_gold = preprocess(vocab_dict, train)\n",
    "test_gold = preprocess(vocab_dict, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa246114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong tập train_gold: 611\n",
      "Số lượng từ trong tập test_gold: 186\n"
     ]
    }
   ],
   "source": [
    "print('Số lượng từ trong tập train_gold:', len(train_gold_words))\n",
    "print('Số lượng từ trong tập test_gold:', len(test_gold_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Các từ không nằm trong vocabs', end=': ')\n",
    "for word in zip(test_gold):\n",
    "    if word == '<unk>': \n",
    "        print(word_tag.split()[0], end=', ')\n",
    "plot_tag_counts(test_gold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
